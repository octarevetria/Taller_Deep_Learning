{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFDq4IxV9kjk"
      },
      "source": [
        "# Mi primera red neuronal 🚀\n",
        "\n",
        "En esta notebook, vamos a explorar la implementación de una red neuronal simple conocida como perceptrón. Un perceptrón es una unidad básica de una red neuronal que puede utilizarse para resolver problemas de clasificación binaria, como las funciones lógicas.\n",
        "\n",
        "## Objetivos de Aprendizaje\n",
        "\n",
        "Al final de esta notebook, serás capaz de:\n",
        "\n",
        "1. Implementar un perceptrón simple en con las funciones lógicas (AND, OR, XOR) vistas en clase de dos formas diferentes:\n",
        "    - Utilizando multiplicación de matrices ($sgn\\left( X \\, W \\right)$).\n",
        "    - Utilizando el sesgo ($sgn\\left( X \\, W + b \\right)$).\n",
        "2. [Opcional] Implementar el resto de las funciones lógicas (NAND, NOR, XNOR) utilizando perceptrones.\n",
        "3. Implementar una Perceptrón Multicapa (MLP) para resolver el problema XOR.\n",
        "4. [Opcional] Implementar un MLP para resolver las todas las funciones lógicas al mismo tiempo (AND, OR, XOR).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eURfGgTu9kjm"
      },
      "source": [
        "## Implementación de un Perceptrón\n",
        "\n",
        "Un perceptrón es una unidad básica de una red neuronal que puede utilizarse para resolver problemas de clasificación binaria.\n",
        "\n",
        "$$\n",
        "\\mathcal{P}(x; w) = sgn(x\\, w) = sgn\\left( \\sum_i x_i w_i \\right)\n",
        "\\quad x, w \\in \\mathbb{R}^m\n",
        "$$\n",
        "con\n",
        "$$\n",
        " sgn(u) =\n",
        "  \\begin{cases}\n",
        "   +1 & \\text{if } u \\geq 0 \\\\\n",
        "   -1 & \\text{if } u < 0\n",
        "  \\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8h6NsrG9kjn"
      },
      "source": [
        "En forma vectorial\n",
        "\n",
        "$$\\mathcal{P}(X; W) = sgn\\left( X \\, W \\right) \\quad X \\in \\mathbb{R}^{(n,m)}, \\, W \\in \\mathbb{R}^{(m,1)}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AND\n",
        "\n",
        "La función lógica AND es una función que toma dos entradas binarias y devuelve 1 si ambas entradas son 1, y 0 en cualquier otro caso.\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 0   |\n",
        "| 0     | 1     | 0   |\n",
        "| 1     | 0     | 0   |\n",
        "| 1     | 1     | 1   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Implementación con multiplicación de matrices\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "  0 & 0 & 1 \\\\\n",
        "  0 & 1 & 1 \\\\\n",
        "  1 & 0 & 1 \\\\\n",
        "  1 & 1 & 1 \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "\\textbf{AND}\\left( X \\right) =\n",
        " \\begin{pmatrix}\n",
        "  -1 \\\\\n",
        "  -1 \\\\\n",
        "  -1 \\\\\n",
        "  1  \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "n = 4\n",
        "$$\n",
        "\n",
        "> Notar que los valores esperados son -1 y 1 en lugar de 0 y 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPwofV509kjo"
      },
      "source": [
        "$$\n",
        "\\textbf{AND}\\left(X \\right) = sgn\\left( X \\,   \n",
        "    \\begin{pmatrix}\n",
        "      .5 \\\\\n",
        "      .5 \\\\\n",
        "      -1 \\\\\n",
        "    \\end{pmatrix} \\right)\n",
        "    \\quad\n",
        "    m = 3\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos a trabajar con PyTorch (tensores) para las operaciones matriciales\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definimos la función `sgn` que aplica la función signo a un número.\n",
        "\n",
        "> Nota: pytorch tiene una función `torch.sign` pero difiere cuando la entrada es 0. En este caso, `torch.sign` devuelve 0 y `sgn` devuelve 1.\n",
        "Más información en: https://pytorch.org/docs/stable/generated/torch.sign.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sgn(x):\n",
        "    return torch.where(x >= 0, 1.0, -1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definimos `X` y `W` como tensores de pytorch, es importante definir el tipo de dato como `torch.float32` para que las operaciones matriciales se realicen correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = torch.tensor([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "\n",
        "# TODO\n",
        "# W_and ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por último, calculamos el resultado de la función AND."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def AND(Input):\n",
        "    # TODO\n",
        "    # return \n",
        "\n",
        "print(f\"{AND(X) = }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que el resultado es el esperado.\n",
        "\n",
        "$$\n",
        "\\textbf{AND}\\left( X \\right) =\n",
        " \\begin{pmatrix}\n",
        "  -1 \\\\\n",
        "  -1 \\\\\n",
        "  -1 \\\\\n",
        "  1  \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = AND(torch.tensor([1, 0, 1], dtype=torch.float32))\n",
        "print(f\"{res = }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Implementación con sesgo (X W + b)\n",
        "\n",
        "Ahora vamos a implementar la función AND utilizando un sesgo, es decir agregando un término adicional a la multiplicación de matrices.\n",
        "\n",
        "Por lo cual nuestro X ahora es de la forma:\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "  0 & 0 \\\\\n",
        "  0 & 1 \\\\\n",
        "  1 & 0 \\\\\n",
        "  1 & 1 \\\\\n",
        " \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "Y nuestro W y b son:\n",
        "\n",
        "$$\n",
        "W = \\begin{pmatrix}\n",
        "  .5 \\\\\n",
        "  .5 \\\\\n",
        "  \\end{pmatrix}\n",
        "\\qquad\n",
        "b = -1\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "\n",
        "# TODO\n",
        "# W_and =\n",
        "# b ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def AND(Input):\n",
        "    # TODO\n",
        "    # return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notar `b` hace brodcasting, ya que es un escalar y `X` es una matriz.\n",
        "\n",
        "Más información en:\n",
        "- https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
        "- https://pytorch.org/docs/stable/notes/broadcasting.html "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AND(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### OR\n",
        "\n",
        "La función lógica OR es una función que toma dos entradas binarias y devuelve 1 si al menos una de las entradas es 1, y 0 en cualquier otro caso.\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 0   |\n",
        "| 0     | 1     | 1   |\n",
        "| 1     | 0     | 1   |\n",
        "| 1     | 1     | 1   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Implementación con multiplicación de matrices\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "  0 & 0 & 1 \\\\\n",
        "  0 & 1 & 1 \\\\\n",
        "  1 & 0 & 1 \\\\\n",
        "  1 & 1 & 1 \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "\\textbf{OR}\\left( X \\right) =\n",
        " \\begin{pmatrix}\n",
        "  -1 \\\\\n",
        "  1 \\\\\n",
        "  1 \\\\\n",
        "  1  \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "n = 4\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "\\textbf{OR}\\left(X \\right) = sgn\\left( X \\,   \n",
        "    \\begin{pmatrix}\n",
        "      ? \\\\\n",
        "      ? \\\\\n",
        "      ? \\\\\n",
        "    \\end{pmatrix} \\right)\n",
        "    \\quad\n",
        "    m = 3\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = torch.tensor([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "\n",
        "# TODO\n",
        "# W_nor ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def OR(Input):\n",
        "    # TODO\n",
        "    # return\n",
        "\n",
        "\n",
        "print(f\"{OR(X) = }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Implementación con sesgo (X W + b)\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "  0 & 0 \\\\\n",
        "  0 & 1 \\\\\n",
        "  1 & 0 \\\\\n",
        "  1 & 1 \\\\\n",
        " \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "Y nuestro W y b son:\n",
        "\n",
        "$$\n",
        "W = \\begin{pmatrix}\n",
        "  ? \\\\\n",
        "  ? \\\\\n",
        "  \\end{pmatrix}\n",
        "\\qquad\n",
        "b = ?\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XOR\n",
        "\n",
        "La función lógica XOR es una función que toma dos entradas binarias y devuelve 1 si las entradas son diferentes, y 0 si son iguales.\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 0   |\n",
        "| 0     | 1     | 1   |\n",
        "| 1     | 0     | 1   |\n",
        "| 1     | 1     | 0   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Implementación con multiplicación de matrices\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "  0 & 0 & 1 \\\\\n",
        "  0 & 1 & 1 \\\\\n",
        "  1 & 0 & 1 \\\\\n",
        "  1 & 1 & 1 \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "\\textbf{XOR}\\left( X \\right) =\n",
        " \\begin{pmatrix}\n",
        "  -1 \\\\\n",
        "  1 \\\\\n",
        "  1 \\\\\n",
        "  -1  \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "n = 4\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "\\textbf{XOR}\\left(X \\right) = sgn\\left( X \\,   \n",
        "    \\begin{pmatrix}\n",
        "      ? \\\\\n",
        "      ? \\\\\n",
        "      ? \\\\\n",
        "    \\end{pmatrix} \\right)\n",
        "    \\quad\n",
        "    m = 3\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [Opcional] Implementar el resto de las funciones lógicas (NAND, NOR, XNOR) utilizando perceptrones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### NAND\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 1   |\n",
        "| 0     | 1     | 1   |\n",
        "| 1     | 0     | 1   |\n",
        "| 1     | 1     | 0   |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### NOR\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 1   |\n",
        "| 0     | 1     | 0   |\n",
        "| 1     | 0     | 0   |\n",
        "| 1     | 1     | 0   |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### NXOR\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 1   |\n",
        "| 0     | 1     | 0   |\n",
        "| 1     | 0     | 0   |\n",
        "| 1     | 1     | 1   |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XOR con Perceptrón Multicapa (MLP)\n",
        "\n",
        "Para resolver el problema XOR, necesitamos una red neuronal más compleja, como una Perceptrón Multicapa (MLP)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Entradas\n",
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "# Salidas esperadas\n",
        "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definimos el modelo\n",
        "\n",
        "class XORNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XORNet, self).__init__()\n",
        "        # TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO\n",
        "        \n",
        "# Aternativa\n",
        "# xor_seq = torch.nn.Sequential(\n",
        "#     pass\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instanciamos\n",
        "model = XORNet()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# training loop\n",
        "epochs = 10_000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # traing mode\n",
        "\n",
        "    output = model(X)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()  # reseteamos los gradientes\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 1_000 == 0:\n",
        "        print(f\"Epoch [{(epoch + 1)}/epochs], Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluando el modelo\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [Opcional] Implementar una MLP para resolver las todas las funciones lógicas al mismo tiempo (AND, OR y XOR).\n",
        "\n",
        "\n",
        "| $x_1$ | $x_2$ | $y_{AND}$ | $y_{OR}$ | $y_{XOR}$ |\n",
        "|-------|-------|-----------|----------|-----------|\n",
        "| 0     | 0     | 0         | 0        | 0         |\n",
        "| 0     | 1     | 0         | 1        | 1         |\n",
        "| 1     | 0     | 0         | 1        | 1         |\n",
        "| 1     | 1     | 1         | 1        | 0         |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entradas\n",
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "# Salidas esperadas\n",
        "y = torch.tensor([[0, 0, 0], [0, 1, 1], [0, 1, 1], [1, 1, 0]], dtype=torch.float32)\n",
        "\n",
        "# TODO..."
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
