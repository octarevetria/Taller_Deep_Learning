{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a PyTorch\n",
    "\n",
    "\n",
    "[PyTorch](https://pytorch.org/) es una biblioteca de aprendizaje profundo de código abierto basada en el lenguaje de programación Python. Desarrollada por Facebook's AI Research lab, PyTorch se ha convertido en una de las herramientas más populares en el campo de la inteligencia artificial y el aprendizaje automático. En esta notebook, vamos a explorar los conceptos básicos de PyTorch con su unidad de cálculo básica, el [tensor](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html).\n",
    "\n",
    "Esta notebook esta basada en:\n",
    "\n",
    "- Joe Papa. (2021). _PyTorch Pocket Reference: Building and Deploying Deep Learning Models_. O'Reilly Media, Inc.\n",
    "- [Learning PyTorch with Examples](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)\n",
    "- [d2l - Data Manipulation](https://d2l.ai/chapter_preliminaries/ndarray.html)\n",
    "- [d2l - Linear Algebra](https://d2l.ai/chapter_preliminaries/linear-algebra.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es un tensor?\n",
    "\n",
    "Un [tensor](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html) es una matriz multidimensional que puede contener datos de diferentes tipos (por ejemplo, números enteros, flotantes, etc.). Los tensores son similares a los arreglos de NumPy, pero con la diferencia de que los tensores pueden ser utilizados en una GPU para acelerar los cálculos. En PyTorch, los tensores son la unidad básica de cálculo y se pueden crear de varias maneras.\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*8jdzMrA33Leu3j3F6A8a3w.png\" width=\"500\" alt=\"PyTorch logo\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de tensores\n",
    "\n",
    "Se pueden crear tensores de varias maneras en PyTorch. A continuación, se van a mostrar algunos ejemplos comunes de cómo crear tensores en PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desde estructuras de datos\n",
    "\n",
    "Podemos crear un tensor a partir de una lista de Python, una tupla, una matriz de NumPy, etc. Para ello, podemos utilizar la función [torch.tensor()](https://pytorch.org/docs/stable/generated/torch.tensor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])  # creamos a partir de una lista\n",
    "y = torch.tensor((1, 2, 3))  # creamos a partir de una tupla\n",
    "z = torch.tensor(np.array([1, 2, 3]))  # creamos a partir de un array de numpy  (si se crea con as_tensor(np) comparte memoria)\n",
    "\n",
    "print(f\"{ x = }\")\n",
    "print(f\"{ y = }\")\n",
    "print(f\"{ z = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con diferentes dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(5)  # 0 dimensiones - escalar\n",
    "x = torch.tensor([5, 4, 3])  # 1 dimension - vector\n",
    "y = torch.tensor([[5, 4, 3], [2, 1, 0]])  # 2 dimensiones - matriz\n",
    "z = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])  # N dimensiones - tensor de orden N\n",
    "\n",
    "print(f\"{ w = }\\n\")\n",
    "print(f\"{ x = }\\n\")\n",
    "print(f\"{ y = }\\n\")\n",
    "print(f\"{ z = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tensores pueden contener datos de diferentes tipos, como enteros, flotantes, etc. Lo importante es que todos los elementos de un tensor deben ser del mismo tipo. Si no se especifica el tipo de datos, PyTorch inferirá el tipo de datos del tensor.\n",
    "Para saber todos los tipos de datos que se pueden utilizar en PyTorch, puedes consultar la [documentación oficial](https://pytorch.org/docs/stable/tensors.html#data-types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([1, 2, 3], dtype=torch.uint8)  # tipo de dato uint8 (0-255)\n",
    "w = torch.tensor([1, 2, 3], dtype=torch.int32)  # tipo de dato int32\n",
    "x = torch.tensor([1, 2, 3], dtype=torch.long)  # tipo de dato int64 o long\n",
    "y = torch.tensor([1, 2, 3], dtype=torch.float32)  # tipo de dato float32\n",
    "z = torch.tensor([False, True, False], dtype=torch.bool)  # tipo de dato booleano\n",
    "\n",
    "print(f\"{ v = }\")\n",
    "print(f\"{ w = }\")\n",
    "print(f\"{ x = }\")\n",
    "print(f\"{ y = }\")\n",
    "print(f\"{ z = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicios:\n",
    "\n",
    "- ¿Qué dato utilizarías para una imagen RGB?\n",
    "- ¿Qué dato utilizarías para el etiquetado de una imagen (clases 0-9)?\n",
    "- ¿Qué dato utilizarías para los pesos de una red neuronal?\n",
    "- ¿Qué dato utilizarías para las probabilidades de salida de un clasificador?\n",
    "- ¿Qué dato utilizarías para una máscara binaria que indica píxeles válidos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver el tipo de datos de un tensor utilizando el atributo `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{ v.dtype = }\")\n",
    "print(f\"{ w.dtype = }\")\n",
    "print(f\"{ x.dtype = }\")\n",
    "print(f\"{ y.dtype = }\")\n",
    "print(f\"{ z.dtype = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desde tensores existentes\n",
    "\n",
    "Podemos crear un tensor a partir de un tensor existente utilizando el método [torch.clone()](https://pytorch.org/docs/stable/generated/torch.clone.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "y = x  # y apunta a la misma dirección de memoria que x\n",
    "z = x.clone()  # z apunta a una nueva dirección de memoria\n",
    "\n",
    "y[0] = 100  # cambia el valor de x\n",
    "\n",
    "print(f\"{ x = }\")\n",
    "print(f\"{ y = }\")\n",
    "print(f\"{ z = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: el método `clone()` es diferenciable, lo que significa que los gradientes se pueden propagar a través de él. Utiliza el método `detach()` si no quieres que los gradientes se propaguen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio: ¿Qué imprime el siguiente código?\n",
    "\n",
    "```python\n",
    "original = torch.tensor([10, 20, 30])\n",
    "reference = original\n",
    "copy = original.clone()\n",
    "copy_reference = copy\n",
    "\n",
    "original += 5\n",
    "copy_reference -= 5\n",
    "\n",
    "print(f\"original = {original}\")\n",
    "print(f\"reference = {reference}\")\n",
    "print(f\"copy = {copy}\")\n",
    "print(f\"copy_reference = {copy_reference}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desde funciones\n",
    "\n",
    "Existen varias funciones en PyTorch que nos permiten crear tensores con valores específicos. Algunas de estas funciones son:\n",
    "\n",
    "- [torch.zeros()](https://pytorch.org/docs/stable/generated/torch.zeros.html): crea un tensor con todos los elementos establecidos en cero.\n",
    "- [torch.ones()](https://pytorch.org/docs/stable/generated/torch.ones.html): crea un tensor con todos los elementos establecidos en uno.\n",
    "- [torch.rand()](https://pytorch.org/docs/stable/generated/torch.rand.html): crea un tensor con valores aleatorios entre 0 y 1.\n",
    "- [torch.randn()](https://pytorch.org/docs/stable/generated/torch.randn.html): crea un tensor con valores aleatorios de una distribución normal.\n",
    "- [torch.arange()](https://pytorch.org/docs/stable/generated/torch.arange.html): crea un tensor con valores espaciados uniformemente dentro de un rango.\n",
    "- [torch.full()](https://pytorch.org/docs/stable/generated/torch.full.html): crea un tensor con todos los elementos establecidos en un valor específico.\n",
    "\n",
    "\n",
    "Muchos de estos métodos reciben como argumento la forma del tensor que queremos crear. Por ejemplo, si queremos crear un tensor de 2x3 con todos los elementos establecidos en cero, podemos hacerlo de la siguiente manera:\n",
    "\n",
    "```python\n",
    "torch.zeros(2, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros((2, 3))  # tensor de 2x3 con ceros (float32)\n",
    "print(f\"{ zeros = }\\n\")\n",
    "\n",
    "zeros = torch.zeros((2, 3), dtype=torch.uint8)  # tensor de 2x3 con ceros (uint8)\n",
    "print(f\"{ zeros = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = torch.ones((5,))  # tensor de 5 elementos con unos\n",
    "print(f\"{ ones = }\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = torch.rand(3, 4)  # tensor de 3x4 con valores aleatorios entre 0 y 1\n",
    "print(f\"{ rand = }\\n\")\n",
    "\n",
    "randn = torch.randn(\n",
    "    3, 4\n",
    ")  # tensor de 3x4 con valores aleatorios de una distribución normal\n",
    "print(f\"{ randn = }\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrange = torch.arange(0, 100, 5)  # tensor con valores de 0 a 10 con paso de 2\n",
    "print(f\"{ arrange = }\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_of_5 = torch.full((3, 3), 5)  # tensor de 3x3 con todos los elementos en 5\n",
    "print(f\"{ full_of_5 = }\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones `_like`\n",
    "\n",
    "A veces, necesitamos crear un tensor con la misma forma que otro tensor. Para ello, PyTorch proporciona funciones que nos permiten crear tensores con la misma forma que otro tensor. Algunos ejemplos de estas funciones son:\n",
    "\n",
    "- [torch.zeros_like()](https://pytorch.org/docs/stable/generated/torch.zeros_like.html): crea un tensor con la misma forma que otro tensor con todos los elementos establecidos en cero.\n",
    "- [torch.ones_like()](https://pytorch.org/docs/stable/generated/torch.ones_like.html): crea un tensor con la misma forma que otro tensor con todos los elementos establecidos en uno.\n",
    "- [torch.rand_like()](https://pytorch.org/docs/stable/generated/torch.rand_like.html): crea un tensor con la misma forma que otro tensor con valores aleatorios entre 0 y 1.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "print(f\"{ torch.zeros_like(x) = }\\n\")\n",
    "print(f\"{ torch.zeros_like(y) = }\\n\")\n",
    "\n",
    "print(f\"{ torch.ones_like(x) = }\\n\")\n",
    "print(f\"{ torch.ones_like(y) = }\\n\")\n",
    "\n",
    "print(f\"{ torch.rand_like(x) = }\\n\")\n",
    "print(f\"{ torch.rand_like(y) = }\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atributos de un tensor\n",
    "\n",
    "Los tensores en PyTorch tienen varios atributos que nos permiten acceder a información sobre el tensor. Algunos de los atributos más comunes son:\n",
    "\n",
    "- [dtype](https://pytorch.org/docs/stable/tensor_attributes.html#torch-dtype): devuelve el tipo de datos del tensor.\n",
    "- [shape](https://pytorch.org/docs/stable/generated/torch.Tensor.shape.html): devuelve la forma/dimensiones del tensor. También podemos utilizar el método [size()](https://pytorch.org/docs/stable/generated/torch.Tensor.size.html) para obtener la forma del tensor.\n",
    "- [ndim](https://pytorch.org/docs/stable/generated/torch.Tensor.ndim.html): devuelve el número de dimensiones del tensor. También podemos utilizar el método [dim()](https://pytorch.org/docs/stable/generated/torch.Tensor.dim.html) para obtener el número de dimensiones del tensor.\n",
    "- [device](https://pytorch.org/docs/stable/generated/torch.Tensor.device.html): devuelve el dispositivo en el que se encuentra el tensor (CPU MPS o GPU).\n",
    "- [requires_grad](https://pytorch.org/docs/stable/generated/torch.Tensor.requires_grad.html): indica si el tensor requiere cálculo de gradientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(f\"{ x.shape = }\")\n",
    "print(f\"{ x.size() = }\\n\")\n",
    "\n",
    "print(\n",
    "    f\"{ y.size() = }\"\n",
    ")  # si no se pone argumento, devuelve una tupla con las dimensiones\n",
    "print(f\"{ y.size(0) = }\")  # devuelve el tamaño de la primera dimensión\n",
    "print(f\"{ y.size(1) = }\")  # devuelve el tamaño de la segunda dimensión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(f\"{ x.ndim = }\")\n",
    "print(f\"{ x.dim() = }\\n\")\n",
    "\n",
    "print(f\"{ y.ndim = }\")\n",
    "print(f\"{ y.dim() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(f\"{x.device = }\")  # cpu es el dispositivo por defecto\n",
    "\n",
    "if torch.cuda.is_available():  # si hay una GPU disponible (y cuda está instalado)\n",
    "    x = x.to(\"cuda\")  # movemos el tensor a la GPU\n",
    "    print(\"x movido a la GPU\")\n",
    "    print(f\"{x.device = }\")\n",
    "\n",
    "if (\n",
    "    torch.backends.mps.is_available()\n",
    "):  # si hay un MPS disponible (https://pytorch.org/docs/stable/mps.html)\n",
    "    x = x.to(\"mps\")\n",
    "    print(\"x movido a MPS\")\n",
    "    print(f\"{x.device = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma es crear el tensor directamente en el dispositivo que queremos utilizando el argumento `device`. Por ejemplo, si queremos crear un tensor en la GPU, podemos hacerlo de la siguiente manera:\n",
    "\n",
    "```python\n",
    "torch.zeros(2, 3, device='cuda')\n",
    "```\n",
    "\n",
    "Es importante verificar que el dispositivo esté disponible antes de crear un tensor en él."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operadores aritméticos\n",
    "\n",
    "Existen varias operaciones que podemos realizar con tensores en PyTorch. Algunas de las operaciones más comunes son:\n",
    "\n",
    "- [Suma](https://pytorch.org/docs/stable/generated/torch.add.html): podemos sumar dos tensores utilizando el operador `+` o la función `torch.add()`.\n",
    "- [Resta](https://pytorch.org/docs/stable/generated/torch.sub.html): podemos restar dos tensores utilizando el operador `-` o la función `torch.sub()`.\n",
    "- [Multiplicación](https://pytorch.org/docs/stable/generated/torch.mul.html): podemos multiplicar dos tensores utilizando el operador `*` o la función `torch.mul()`.\n",
    "- [División](https://pytorch.org/docs/stable/generated/torch.div.html): podemos dividir dos tensores utilizando el operador `/` o la función `torch.div()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([1, 5, 10])\n",
    "\n",
    "print(f\"{x + y = }\")\n",
    "print(f\"{x - y = }\")\n",
    "print(f\"{x * y = }\")\n",
    "print(f\"{x / y = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones in-place\n",
    "\n",
    "PyTorch también proporciona operaciones in-place que modifican el tensor original. Estas operaciones tienen un guion bajo al final del nombre de la función. Estas operaciones son más eficientes en términos de memoria y tiempo de ejecución, ya que no crean un nuevo tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([1, 5, 10])\n",
    "\n",
    "x.add(y)  # suma x e y y guarda el resultado en una nueva variable\n",
    "print(f\"{ x = }\")\n",
    "\n",
    "x.add_(y)  # suma y guarda el resultado en x\n",
    "print(f\"{ x = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "PyTorch también admite [broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html), que es una técnica que permite a PyTorch realizar operaciones entre tensores de diferentes formas. PyTorch realiza broadcasting automáticamente cuando es posible. Por ejemplo, si tenemos un tensor de forma (2, 3) y queremos sumar un escalar a él, PyTorch realizará broadcasting automáticamente para que la operación sea válida. Toma la [idea de NumPy](https://numpy.org/doc/stable/user/basics.broadcasting.html) y la implementa de manera eficiente en PyTorch.\n",
    "\n",
    "Reglas de broadcasting:\n",
    "\n",
    "- Cada tensor tiene al menos una dimensión.\n",
    "- Al iterar sobre los tamaños de dimensión, empezando por la dimensión final (der a izq), los tamaños de dimensión deben cumplir con alguna de estas condiciones: \n",
    "    - ser iguales\n",
    "    - uno de ellos es 1\n",
    "    - uno de ellos no existe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(5, 7, 3)\n",
    "y = torch.empty(5, 7, 3)\n",
    "# son broadcasteables porque sus dimensiones son iguales\n",
    "\n",
    "x = torch.empty((0,))\n",
    "y = torch.empty(2, 2)\n",
    "# no son broadcasteables porque x no tiene dimensiones (rompe la regla 1)\n",
    "\n",
    "x = torch.empty(5, 3, 4, 1)\n",
    "y = torch.empty(3, 1, 1)\n",
    "# x e y son broadcastables.\n",
    "# 1st dimension: son iguales\n",
    "# 2nd dimension: y tiene un tamaño de 1\n",
    "# 3rd dimension: son iguales\n",
    "# 4th dimension: y falta\n",
    "\n",
    "x = torch.empty(5, 2, 4, 1)\n",
    "y = torch.empty(3, 1, 1)\n",
    "# no son broadcasteables porque la 3nd dimension x es diferente de la 3rd dimension de y (2 != 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([3])\n",
    "z = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(f\"{x.size() = }\")\n",
    "print(f\"{y.size() = }\")\n",
    "print(f\"{z.size() = }\\n\")\n",
    "\n",
    "print(f\"{x + y = }\")\n",
    "print(f\"{x + z = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicios:\n",
    "```python\n",
    "a = torch.randn(3, 1, 5)    # shape: [3, 1, 5]\n",
    "b = torch.randn(2, 4, 1)    # shape: [2, 4, 1]\n",
    "# ¿Se puede hacer: result = a + b?\n",
    "\n",
    "\n",
    "x = torch.randn(128, 1, 1)     # shape: [128, 1, 1]\n",
    "y = torch.randn(1, 64, 32)     # shape: [1, 64, 32]\n",
    "# ¿Se puede hacer: result = x * y?\n",
    "\n",
    "tensor_a = torch.randn(5, 3, 2)    # shape: [5, 3, 2]\n",
    "tensor_b = torch.randn(3, 4)       # shape: [3, 4]\n",
    "# ¿Se puede hacer: result = tensor_a - tensor_b?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexación y slicing\n",
    "\n",
    "Podemos acceder a los elementos de un tensor utilizando la indexación y el slicing. La indexación en PyTorch es similar a la indexación en NumPy. Podemos acceder a los elementos de un tensor utilizando corchetes `[]`. También podemos utilizar el slicing para acceder a subtensores de un tensor. La indexación y el slicing en PyTorch son de estilo Python, lo que significa que el índice de inicio es inclusivo y el índice de parada es exclusivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "print(f\"{x[0] = }\")  # primer elemento\n",
    "print(f\"{x[2] = }\")  # tercer elemento\n",
    "print(f\"{x[-1] = }\\n\")  # último elemento\n",
    "\n",
    "print(f\"{x[1:3] = }\")  # elementos 1 y 2\n",
    "print(f\"{x[2:] = }\")  # elementos desde el 2 en adelante\n",
    "print(f\"{x[:4] = }\\n\")  # elementos hasta el 4\n",
    "\n",
    "print(f\"{x[::2] = }\")  # elementos con paso de 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quizás nos interesaría tomar un valor específico de un tensor. Para ello, podemos utilizar el método [item()](https://pytorch.org/docs/stable/generated/torch.Tensor.item.html). <- Muy útil para obtener un valor escalar de un tensor, por ejemplo la loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "print(f\"{x[0] = }\")\n",
    "print(f\"{x[0].item() = }\")  # solo funciona con tensores de un solo elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # matriz 3x3\n",
    "\n",
    "print(f\"{x[0, 0] = }\")  # primer elemento\n",
    "print(f\"{x[1, 2] = }\")  # elemento de la segunda fila y tercera columna\n",
    "print(f\"{x[-1, -1] = }\\n\")  # último elemento de la última fila\n",
    "\n",
    "print(f\"{x[1, :] = }\")  # segunda fila\n",
    "print(f\"{x[:, 2] = }\")  # tercera columna\n",
    "print(\n",
    "    f\"{x[1:, :2] = }\"\n",
    ")  # desde la segunda fila hasta el final y desde la primera columna hasta la segunda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten en cuenta que la indexación y el slicing en PyTorch devuelven [vistas](https://pytorch.org/docs/stable/tensor_view.html) del tensor original, no copias. Esto significa que si modificamos el tensor resultante, también se modificará el tensor original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # matriz 3x3\n",
    "y = x[:, 1] # segunda columna\n",
    "\n",
    "y[0] = 100  # cambia el valor de x\n",
    "\n",
    "print(f\"{x = }\\n\")\n",
    "\n",
    "# podemos chequear si dos tensores comparten memoria\n",
    "if x.untyped_storage().data_ptr() == y.untyped_storage().data_ptr():\n",
    "    print(\"x e y comparten memoria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mascaras booleanas\n",
    "\n",
    "Podemos utilizar máscaras booleanas para indexar tensores en PyTorch. Una máscara booleana es un tensor que contiene valores booleanos (True o False) y se utiliza para seleccionar elementos de un tensor. Veamos algunos ejemplos de cómo utilizar máscaras booleanas en PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([True, False, True, True])\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "print(f\"{x[mask] = }\")\n",
    "print(f\"{x > 2 = }\")\n",
    "print(f\"{x[x > 2] = }\")\n",
    "print(f\"{(x * mask).sum() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([True, False, True])\n",
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "y = torch.zeros_like(x)\n",
    "y[mask] = x[mask]\n",
    "\n",
    "print(f\"{y = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicios: Qué imprime el siguiente código?\n",
    "\n",
    "```python\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # matriz 3x3\n",
    "mask = torch.tensor([True, False, True])  # máscara booleana\n",
    "print(f\"{x[mask] = }\")\n",
    "print(f\"{x > 2 = }\")\n",
    "print(f\"{x[x > 2] = }\")\n",
    "print(f\"{(x * mask).sum() = }\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de reducción y agregación\n",
    "\n",
    "PyTorch proporciona varias funciones de reducción que nos permiten reducir un tensor a un solo valor. Algunas de las funciones de reducción más comunes son:\n",
    "\n",
    "- [torch.sum()](https://pytorch.org/docs/stable/generated/torch.sum.html): calcula la suma de todos los elementos de un tensor.\n",
    "- [torch.mean()](https://pytorch.org/docs/stable/generated/torch.mean.html): calcula la media de todos los elementos de un tensor.\n",
    "- [torch.max()](https://pytorch.org/docs/stable/generated/torch.max.html): calcula el valor máximo de un tensor.\n",
    "- [torch.min()](https://pytorch.org/docs/stable/generated/torch.min.html): calcula el valor mínimo de un tensor.\n",
    "- [torch.argmax()](https://pytorch.org/docs/stable/generated/torch.argmax.html): devuelve el índice del valor máximo de un tensor.\n",
    "- [torch.argmin()](https://pytorch.org/docs/stable/generated/torch.argmin.html): devuelve el índice del valor mínimo de un tensor.\n",
    "\n",
    "Estas funciones también aceptan un argumento `dim` que nos permite especificar la dimensión a lo largo de la cual queremos realizar la reducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32)\n",
    "\n",
    "print(f\"{torch.sum(x) = }\")  # suma de todos los elementos\n",
    "print(f\"{torch.sum(x, dim=0) = }\")  # suma de cada columna\n",
    "print(f\"{torch.sum(x, dim=1) = }\\n\")  # suma de cada fila\n",
    "\n",
    "print(f\"{torch.mean(x) = }\")  # media de todos los elementos\n",
    "print(f\"{torch.mean(x, dim=0) = }\")  # media de cada columna\n",
    "print(f\"{torch.mean(x, dim=1) = }\\n\")  # media de cada fila\n",
    "\n",
    "print(f\"{torch.max(x) = }\")  # máximo de todos los elementos\n",
    "print(f\"{torch.max(x, dim=0) = }\")  # máximo de cada columna\n",
    "print(f\"{torch.max(x, dim=1) = }\\n\")  # máximo de cada fila\n",
    "\n",
    "print(f\"{torch.min(x) = }\")  # mínimo de todos los elementos\n",
    "print(f\"{torch.min(x, dim=0) = }\")  # mínimo de cada columna\n",
    "print(f\"{torch.min(x, dim=1) = }\\n\")  # mínimo de cada fila\n",
    "\n",
    "print(\n",
    "    f\"{torch.argmax(x) = }\"\n",
    ")  # índice del máximo de todos los elementos, como es una matriz, devuelve el índice en el array plano\n",
    "print(f\"{torch.argmax(x, dim=0) = }\")  # índice del máximo de cada columna\n",
    "print(f\"{torch.argmax(x, dim=1) = }\\n\")  # índice del máximo de cada fila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinación y división\n",
    "\n",
    "PyTorch proporciona varias funciones que nos permiten combinar y dividir tensores. Algunas de las funciones más comunes son:\n",
    "\n",
    "- [torch.cat()](https://pytorch.org/docs/stable/generated/torch.cat.html): combina varios tensores a lo largo de una dimensión específica.\n",
    "- [torch.stack()](https://pytorch.org/docs/stable/generated/torch.stack.html): apila varios tensores a lo largo de una nueva dimensión.\n",
    "- [torch.split()](https://pytorch.org/docs/stable/generated/torch.split.html): divide un tensor en varias partes a lo largo de una dimensión específica.\n",
    "- [torch.chunk()](https://pytorch.org/docs/stable/generated/torch.chunk.html): divide un tensor en varias partes a lo largo de una dimensión específica.\n",
    "- [torch.squeeze()](https://pytorch.org/docs/stable/generated/torch.squeeze.html): elimina dimensiones de tamaño 1 de un tensor.\n",
    "- [torch.unsqueeze()](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html): agrega una dimensión de tamaño 1 a un tensor.\n",
    "- [torch.reshape()](https://pytorch.org/docs/stable/generated/torch.reshape.html): cambia la forma de un tensor.\n",
    "\n",
    "Existen muchas más funciones que nos permiten combinar y dividir tensores en PyTorch. Puedes consultar la [documentación oficial](https://pytorch.org/docs/stable/torch.html) para obtener más información sobre estas funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "y = torch.tensor([5, 4, 3, 2, 1, 0])\n",
    "\n",
    "print(f\"{torch.cat((x, y)) = }\\n\")  # concatenación de tensores\n",
    "print(f\"{torch.stack((x, y)) = }\\n\")  # apilamiento de tensores\n",
    "print(f\"{torch.split(x, 2) = }\\n\")  # división de un tensor en partes de tamaño 2\n",
    "print(f\"{torch.chunk(x, 2) = }\\n\")  # división de un tensor en 2 partes\n",
    "\n",
    "print(\n",
    "    f\"{torch.squeeze(torch.zeros(1, 2, 1, 2)).size() = }\\n\"\n",
    ")  # elimina las dimensiones de tamaño 1\n",
    "print(f\"{torch.unsqueeze(torch.zeros(2, 2), 0).size() = }\")  # añade una dimensión al principio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(9)\n",
    "print(f\"{torch.reshape(x, (3, 3)).size() = }\")  # reorganiza los elementos en una matriz 3x3\n",
    "print(\n",
    "    f\"{torch.reshape(x, (3, -1)).size() = }\"\n",
    ")  # -1 significa que se infiere el tamaño de esa dimensión\n",
    "print(f\"{torch.reshape(x, (-1, 3)).size() = }\\n\")\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "print(f\"{torch.reshape(x, (2, 3)).size() = }\")  # reorganiza los elementos en una matriz 2x3\n",
    "print(f\"{torch.reshape(x, (3, 2)).size() = }\")  # reorganiza los elementos en una matriz 3x2\n",
    "print(f\"{torch.reshape(x, (6, -1)).size() = }\")  # reorganiza los elementos en una matriz 6x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaciones\n",
    "\n",
    "### Elemento a elemento\n",
    "\n",
    "Podemos realizar comparaciones elemento a elemento entre dos tensores utilizando los operadores de comparación estándar (`==`, `!=`, `>`, `<`, `>=`, `<=`). Estos operadores devuelven un tensor de tipo `bool` con el mismo tamaño que los tensores de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([3, 2, 1])\n",
    "\n",
    "print(f\"{ x == y = }\")  # También se puede usar torch.eq(x, y)\n",
    "print(f\"{ x < y = }\")  # También se puede usar torch.lt(x, y)\n",
    "print(f\"{ x > y = }\")  # También se puede usar torch.gt(x, y)\n",
    "print(f\"{ x != y = }\")  # También se puede usar torch.ne(x, y)\n",
    "print(f\"{ x <= y = }\")  # También se puede usar torch.le(x, y)\n",
    "print(f\"{ x >= y = }\")  # También se puede usar torch.ge(x, y)\n",
    "print(f\"{ x % 2 == 0 = }\\n\")  # También se puede usar torch.ge(x, y)\n",
    "\n",
    "print(f\"{ torch.where(x < y, x, y) = }\")  # si x < y, devuelve x, sino y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De reducción\n",
    "\n",
    "PyTorch también proporciona funciones de comparación de reducción que nos permiten comparar un tensor con un valor específico. Algunas de las funciones de comparación de reducción más comunes son:\n",
    "\n",
    "- [torch.all()](https://pytorch.org/docs/stable/generated/torch.all.html): devuelve `True` si todos los elementos de un tensor son verdaderos.\n",
    "- [torch.any()](https://pytorch.org/docs/stable/generated/torch.any.html): devuelve `True` si algún elemento de un tensor es verdadero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([3, 2, 1])\n",
    "\n",
    "print(f\"{torch.all(x > 0) = }\")  # si todos los elementos son mayores a 0\n",
    "print(f\"{torch.any(x < 0) = }\")  # si algún elemento es menor a 0\n",
    "print(f\"{torch.all(x > y) = }\")  # si todos los elementos de x son mayores a los de y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de GPU\n",
    "\n",
    "En PyTorch, podemos utilizar una GPU para acelerar los cálculos. En la siguiente celda contrastamos el tiempo que tarda en realizar una operación en una CPU y en una GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 900000) \n",
    "y = torch.randn(900000, 200)\n",
    "\n",
    "print('CPU time:')\n",
    "%timeit -n 5 -r 3 torch.mm(x, y) # https://docs.python.org/3/library/timeit.html\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x = x.to('cuda')\n",
    "    y = y.to('cuda')\n",
    "\n",
    "    print('\\nGPU time:')\n",
    "    %timeit -n 5 -r 3 torch.mm(x, y)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    x = x.to('mps')\n",
    "    y = y.to('mps')\n",
    "\n",
    "    print('\\nMPS time:')\n",
    "    %timeit -n 5 -r 3 torch.mm(x, y)  # MPS es para Mac con chip M1/M2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "\n",
    "1. Crear un tensor de 2x3 con valores aleatorios entre 0 y 1.\n",
    "2. Crear un tensor de 3x3 con todos los elementos establecidos en cero.\n",
    "3. Crear un tensor de dim 1 de 10 elementos con valores aleatorios con media 5 y varianza 1.\n",
    "4. Crear una función que tome un tensor y devuelva el tensor elevado al cuadrado.\n",
    "    ```python\n",
    "    def square_tensor(tensor):\n",
    "        pass\n",
    "    ```\n",
    "5. Crear una funcion que tome N y M (int) y retorne un tensor de NxM cuyos elementos sean los primeros números pares. Si N=2 y M=3 entonces [[0, 2, 4], [6, 8, 10]].\n",
    "    ```python\n",
    "    def even_tensor(n, m):\n",
    "        pass\n",
    "    ```\n",
    "6. Crear una función que tome un tensor y devuelva el valor máximo y mínimo del tensor.\n",
    "    ```python\n",
    "    def min_max_tensor(tensor):\n",
    "        pass\n",
    "    ```\n",
    "7. Crear una función que tome un tensor y devuelva la media y desviación estándar del tensor.\n",
    "    ```python\n",
    "    def mean_std_tensor(tensor):\n",
    "        pass\n",
    "    ```\n",
    "8. Crear una función que tome un tensor de dimensión 1 y devuelva el tensor con los elementos en orden inverso. Ver: [torch.flip()](https://pytorch.org/docs/stable/generated/torch.flip.html).\n",
    "    ```python\n",
    "    def reverse_tensor(tensor):\n",
    "        pass\n",
    "    ```\n",
    "9. Crear un tensor de NxM con valores aleatorios, obtener la suma de las fila y multiplicar por un valor constante.\n",
    "    ```python\n",
    "    def row_sum_prod(n, m, constant):\n",
    "        pass\n",
    "    ```\n",
    "10. Crear una función que tome dos tensores y determine si existe algún elemento común entre ellos (en la misma posición).\n",
    "    ```python\n",
    "    def has_common_elements(tensor1, tensor2):\n",
    "        pass\n",
    "    ```\n",
    "11. Crear una función que tome un tensor y devuelva el tensor con los elementos únicos.\n",
    "    ```python\n",
    "    def unique_elements(tensor):\n",
    "        pass\n",
    "    ```\n",
    "12. Crear una función que tome dos tensores y retorna un tensor con los elementos comunes (en la misma posición).\n",
    "    ```python\n",
    "    def common_elements(tensor1, tensor2):\n",
    "        pass\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear un tensor de 2x3 con valores aleatorios entre 0 y 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Crear un tensor de 3x3 con todos los elementos establecidos en cero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Crear un vector de 10 elementos con valores aleatorios con media 5 y varianza 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Crear una función que tome un tensor y devuelva el tensor elevado al cuadrado.\n",
    "\n",
    "\n",
    "def square_tensor(tensor):\n",
    "    pass\n",
    "\n",
    "\n",
    "square_tensor(torch.tensor([1, 2, 3]))  # tensor([1, 4, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Crear una funcion que tome N y M (int) y retorne un tensor de NxM cuyos elementos sean los primeros números pares. Si N=2 y M=3 entonces [[0, 2, 4], [6, 8, 10]].\n",
    "\n",
    "\n",
    "def even_tensor(n, m):\n",
    "    pass\n",
    "\n",
    "\n",
    "even_tensor(2, 3)  # tensor([[0, 2, 4], [6, 8, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Crear una función que tome un tensor y devuelva el valor máximo y mínimo del tensor.\n",
    "\n",
    "\n",
    "def min_max_tensor(tensor):\n",
    "    pass\n",
    "\n",
    "\n",
    "min_max_tensor(torch.tensor([1, 2, 3, 4, 5]))  # (5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Crear una funcion que tome tensor y devuelva la media y desviación estándar del tensor.\n",
    "\n",
    "def mean_std_tensor(tensor):\n",
    "    pass\n",
    "\n",
    "\n",
    "mean_std_tensor(torch.arange(10, dtype=torch.float32))  # (4.5, 3.027..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Crear una función que tome un tensor de dimensión 1 y devuelva el tensor con los elementos en orden inverso.\n",
    "\n",
    "\n",
    "def reverse_tensor(tensor):\n",
    "    pass\n",
    "\n",
    "\n",
    "reverse_tensor(torch.tensor([1, 2, 3, 4, 5]))  # tensor([5, 4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Crear un tensor de NxM con valores aleatorios, obtener la suma de las fila y multiplicar por un valor constante.\n",
    "\n",
    "\n",
    "def row_sum_prod(n, m, constant):\n",
    "    pass\n",
    "\n",
    "\n",
    "row_sum_prod(2, 3, 2)  # tensor([_, _])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Crear una función que tome dos tensores y determine si existe algún elemento común entre ellos (en la misma posición).\n",
    "\n",
    "\n",
    "def has_common_elements(tensor1, tensor2):\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\n",
    "    has_common_elements(torch.tensor([1, 2, 3, 4, 5]), torch.tensor([1, 5, 3, 4, 2]))\n",
    ")  # True\n",
    "print(\n",
    "    has_common_elements(torch.tensor([1, 2, 3, 4, 5]), torch.tensor([5, 4, 1, 2, 3]))\n",
    ")  # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Crear una función que tome un tensor y devuelva el tensor (dim=1) con los elementos únicos.\n",
    "\n",
    "\n",
    "def unique_elements(tensor):\n",
    "    pass\n",
    "\n",
    "\n",
    "print(unique_elements(torch.tensor([1, 2, 2, 1, 1, 3, 2, 2])))  # tensor([1, 2, 3])\n",
    "print(\n",
    "    unique_elements(torch.tensor([[1, 2, 3], [1, 2, 3], [1, 2, 4]]))\n",
    ")  # tensor([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Crear una función que tome dos tensores y retorna un tensor con los elementos comunes (en la misma posición).\n",
    "\n",
    "def common_elements(tensor1, tensor2):\n",
    "    pass\n",
    "\n",
    "common_elements(torch.tensor([1, 2, 3, 4, 5]), torch.tensor([1, 5, 3, 4, 2])) # tensor([1, 3, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taller-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
